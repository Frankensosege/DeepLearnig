{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875e380a",
   "metadata": {},
   "source": [
    "# 세상에 없는 얼굴 GAN, 오토인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f131f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 정규화, 이미지 확대, DCGAN\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, Reshape, Input, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Activation, LeakyReLU, UpSampling2D, Conv2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f66a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "# (X_train, _),(_,_) = mnist.load_data()\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a548632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 6272)              633472    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 6272)             25088     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " up_sampling2d_6 (UpSampling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 14, 14, 64)        204864    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " up_sampling2d_7 (UpSampling  (None, 28, 28, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 28, 28, 1)         1601      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 865,281\n",
      "Trainable params: 852,609\n",
      "Non-trainable params: 12,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 생성자 모델생성\n",
    "# 최종 activation 함수로 tanh를 사용 하므로 - 값을 버리면 안됨 -> LeakyReLU를 사용\n",
    "# 만들고자하는 이미지의 사이즈가 28 * 28 인데  UpSampling2D를 두번 하므로 7 * 7\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2)))  # 입력층 -> layer 1 \n",
    "generator.add(BatchNormalization())         # 배치정규화 : 평균 0, 분산이 1인 데이터로 재배치\n",
    "generator.add(Reshape((7, 7, 128)))         # 3차원으로 데이터 타입 변경\n",
    "generator.add(UpSampling2D())               # 이미지를 2배로 확장 시킴\n",
    "generator.add(Conv2D(64, kernel_size=5, padding='same'))   # padding='same', 이미지 사이즈 줄지 않음\n",
    "generator.add(BatchNormalization())         # 배치정규화 : 평균 0, 분산이 1인 데이터로 재배치\n",
    "generator.add(Activation(LeakyReLU(0.2)))   # 활성화 함수 추가\n",
    "generator.add(UpSampling2D())               # 이미지를 2배로 확장 시킴\n",
    "generator.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd10cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 14, 14, 64)        1664      \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 7, 7, 128)         204928    \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 6273      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 0\n",
      "Non-trainable params: 212,865\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 판별자 모델생성\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28, 28, 1), padding='same'))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding='same'))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "discriminator.trainable = False\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75c20d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (None, 28, 28, 1)         865281    \n",
      "                                                                 \n",
      " sequential_8 (Sequential)   (None, 1)                 212865    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,078,146\n",
      "Trainable params: 852,609\n",
      "Non-trainable params: 225,537\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 생성자와 판별자 모델을 연결 시키는 gan 모델 생성\n",
    "ginput = Input(shape=(100))\n",
    "dis_output = discriminator(generator(ginput))\n",
    "gan = Model(ginput, dis_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "906ba8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_train(epoch, batch_size, saving_inteval):\n",
    "    (X_train, _),(_,_) = mnist.load_data()\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float64')\n",
    "    # generator의 activation 함수가 tanh 이므로 데이터를 -1 ~ 1 사이의 값으로 변환(255/2)\n",
    "    X_train = (X_train - 127.5) / 127.5\n",
    "    \n",
    "    true = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "#     gen_imgs = np.random.normal(0, 1, (batch_size, 100))\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        # 실재 이미지를 판별자에 입력\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, true)\n",
    "        \n",
    "        # 가상이미지를 판별자에 입력\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        \n",
    "        # 판별자와 생성자의 오차 계산\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        g_loss = gan.train_on_batch(gen_imgs, true)\n",
    "        \n",
    "        print('epoch: %d' % i, ' d_loss: %.4f' % d_loss, ' g_loss: %.4f' % g_loss)\n",
    "        \n",
    "        if i % saving_inteval == 0:\n",
    "            noise = np.random.normal(0, 1, (25, 100))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "\n",
    "            # rescale images 0 - 1\n",
    "            gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "            fig, axs = plt.subplots(5, 5)\n",
    "            count = 0\n",
    "            for j in range(5):\n",
    "                for k in range(5):\n",
    "                    axs[j,k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
    "                    axs[j,k].axis('off')\n",
    "                    count += 1\n",
    "            fig.savefig('./data/gan_images/gan_mnist_%d.png' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0375748e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\frank\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\frank\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\frank\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\frank\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\frank\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\frank\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_2\" is incompatible with the layer: expected shape=(None, 100), found shape=(100, 28, 28, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgan_train\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[35], line 25\u001b[0m, in \u001b[0;36mgan_train\u001b[1;34m(epoch, batch_size, saving_inteval)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 판별자와 생성자의 오차 계산\u001b[39;00m\n\u001b[0;32m     24\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39madd(d_loss_real, d_loss_fake)\n\u001b[1;32m---> 25\u001b[0m g_loss \u001b[38;5;241m=\u001b[39m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m d_loss: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m d_loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m g_loss: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m g_loss)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m saving_inteval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\training.py:2478\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2474\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[0;32m   2475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[0;32m   2476\u001b[0m     )\n\u001b[0;32m   2477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 2478\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2480\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filee5222c_c.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\training.py:1233\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1229\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1230\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m     )\n\u001b[0;32m   1232\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1233\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1234\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1235\u001b[0m     outputs,\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1237\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1238\u001b[0m )\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\training.py:1222\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1222\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1223\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\training.py:1023\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# Run forward pass.\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m-> 1023\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1024\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\input_spec.py:295\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 295\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    297\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\frank\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\frank\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\frank\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\frank\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\frank\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\frank\\anaconda3\\envs\\py3.8\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_2\" is incompatible with the layer: expected shape=(None, 100), found shape=(100, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "gan_train(2001, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa06c54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = np.random.normal(0, 1, (1, 100))\n",
    "gen_imgs = generator.predict(noise)\n",
    "\n",
    "# rescale images 0 - 1\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "plt.imshow(gen_imgs[0, :, :, 0], cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffca54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
